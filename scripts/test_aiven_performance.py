#!/usr/bin/env python3
"""
Script para probar el rendimiento del dashboard con base de datos de Aiven
Permite verificar que la optimizaciÃ³n funciona antes de subir a producciÃ³n
"""

import requests
import time
import json
import statistics

def test_dashboard_performance():
    """Probar el rendimiento del dashboard con Aiven"""
    
    # ConfiguraciÃ³n local
    base_url = "http://localhost:8000"
    test_user_id = 999  # Cambiado a un ID que probablemente no exista para ver el error real
    
    print("ğŸ§ª TESTER DE RENDIMIENTO - ASTREN CON AIVEN")
    print("=" * 60)
    print("Probando dashboard conectado a base de datos de Aiven")
    print("(La misma que usas en producciÃ³n)")
    print()
    
    # Test 1: Endpoint unificado del dashboard (mÃºltiples pruebas)
    print("ğŸ“Š Test 1: Endpoint unificado del dashboard")
    print("-" * 40)
    
    tiempos_respuesta = []
    exitosos = 0
    total_pruebas = 5
    
    for i in range(total_pruebas):
        print(f"   ğŸ”„ Prueba {i+1}/{total_pruebas}...", end=" ")
        
        start_time = time.time()
        try:
            response = requests.get(f"{base_url}/dashboard/{test_user_id}")
            end_time = time.time()
            
            if response.status_code == 200:
                tiempo = end_time - start_time
                tiempos_respuesta.append(tiempo)
                exitosos += 1
                print(f"âœ… {tiempo:.2f}s")
            else:
                print(f"âŒ Error {response.status_code}")
                
        except Exception as e:
            print(f"âŒ Error: {e}")
    
    if exitosos > 0:
        tiempo_promedio = statistics.mean(tiempos_respuesta)
        tiempo_min = min(tiempos_respuesta)
        tiempo_max = max(tiempos_respuesta)
        
        print(f"\n   ğŸ“Š Resultados:")
        print(f"      âœ… Pruebas exitosas: {exitosos}/{total_pruebas}")
        print(f"      â±ï¸  Tiempo promedio: {tiempo_promedio:.2f}s")
        print(f"      ğŸš€ Tiempo mÃ¡s rÃ¡pido: {tiempo_min:.2f}s")
        print(f"      ğŸŒ Tiempo mÃ¡s lento: {tiempo_max:.2f}s")
        
        # Evaluar rendimiento
        if tiempo_promedio < 1.0:
            print(f"      ğŸ‰ EXCELENTE: Muy rÃ¡pido (< 1s)")
        elif tiempo_promedio < 3.0:
            print(f"      âœ… BUENO: RÃ¡pido (< 3s)")
        elif tiempo_promedio < 10.0:
            print(f"      âš ï¸  ACEPTABLE: Moderado (< 10s)")
        else:
            print(f"      âŒ LENTO: Muy lento (> 10s)")
    else:
        print("   âŒ No se pudo completar ninguna prueba")
        return False
    
    # Test 2: AnÃ¡lisis de datos recibidos
    print("\nğŸ“Š Test 2: AnÃ¡lisis de datos recibidos")
    print("-" * 40)
    
    try:
        response = requests.get(f"{base_url}/dashboard/{test_user_id}")
        if response.status_code == 200:
            data = response.json()
            
            print(f"   ğŸ“‹ Tareas: {len(data.get('tareas', []))}")
            print(f"   ğŸ¯ Ãreas: {len(data.get('areas', []))}")
            print(f"   ğŸ‘¥ Grupos: {len(data.get('grupos', []))}")
            print(f"   ğŸ“Š Contadores: {data.get('contadores', {})}")
            
            # Verificar timestamp
            if 'timestamp' in data:
                print(f"   ğŸ• Timestamp: {data['timestamp']}")
                
        else:
            print(f"   âŒ Error al obtener datos: {response.status_code}")
            
    except Exception as e:
        print(f"   âŒ Error en anÃ¡lisis: {e}")
    
    # Test 3: Verificar headers de optimizaciÃ³n
    print("\nğŸ“Š Test 3: Headers de optimizaciÃ³n")
    print("-" * 40)
    
    try:
        response = requests.get(f"{base_url}/dashboard/{test_user_id}")
        headers = response.headers
        
        cache_control = headers.get('Cache-Control', 'No especificado')
        print(f"   ğŸ—„ï¸  Cache-Control: {cache_control}")
        
        content_type = headers.get('Content-Type', 'No especificado')
        print(f"   ğŸ“„ Content-Type: {content_type}")
        
        # Headers de seguridad
        security_headers = ['X-Content-Type-Options', 'X-Frame-Options', 'X-XSS-Protection']
        for header in security_headers:
            value = headers.get(header, 'No especificado')
            print(f"   ğŸ”’ {header}: {value}")
            
    except Exception as e:
        print(f"   âŒ Error al verificar headers: {e}")
    
    # Test 4: ComparaciÃ³n con rendimiento esperado
    print("\nğŸ“Š Test 4: AnÃ¡lisis de rendimiento")
    print("-" * 40)
    
    if 'tiempo_promedio' in locals():
        print(f"   ğŸ¯ Tiempo promedio actual: {tiempo_promedio:.2f}s")
        
        # Comparar con rendimiento esperado
        if tiempo_promedio < 3.0:
            print("   ğŸš€ RENDIMIENTO: EXCELENTE")
            print("      âœ… Puedes subir a producciÃ³n con confianza")
            print("      âœ… Los Ã­ndices estÃ¡n funcionando perfectamente")
        elif tiempo_promedio < 10.0:
            print("   âš ï¸  RENDIMIENTO: ACEPTABLE")
            print("      ğŸ’¡ Hay margen de mejora")
            print("      ğŸ’¡ Considera revisar antes de subir")
        else:
            print("   âŒ RENDIMIENTO: PROBLEMÃTICO")
            print("      ğŸ”§ Necesita mÃ¡s optimizaciÃ³n")
            print("      ğŸ”§ NO subas a producciÃ³n aÃºn")
    
    # Test 5: VerificaciÃ³n de conexiÃ³n a Aiven
    print("\nğŸ“Š Test 5: VerificaciÃ³n de conexiÃ³n")
    print("-" * 40)
    
    try:
        # Hacer una consulta simple para verificar conexiÃ³n
        start_time = time.time()
        response = requests.get(f"{base_url}/dashboard/{test_user_id}")
        end_time = time.time()
        
        if response.status_code == 200:
            tiempo_conexion = end_time - start_time
            print(f"   âœ… ConexiÃ³n a Aiven: Funcionando")
            print(f"   â±ï¸  Tiempo de respuesta: {tiempo_conexion:.2f}s")
            
            # Evaluar latencia de red
            if tiempo_conexion < 0.5:
                print("   ğŸš€ Latencia: Muy baja (excelente)")
            elif tiempo_conexion < 1.0:
                print("   âœ… Latencia: Baja (buena)")
            elif tiempo_conexion < 3.0:
                print("   âš ï¸  Latencia: Moderada (aceptable)")
            else:
                print("   âŒ Latencia: Alta (problemÃ¡tica)")
        else:
            print(f"   âŒ ConexiÃ³n a Aiven: Error {response.status_code}")
            
    except Exception as e:
        print(f"   âŒ Error de conexiÃ³n: {e}")
    
    # Resumen final
    print("\n" + "=" * 60)
    print("ğŸ¯ RESUMEN FINAL")
    print("=" * 60)
    
    if 'tiempo_promedio' in locals():
        if tiempo_promedio < 3.0:
            print("âœ… RESULTADO: EXCELENTE")
            print("   ğŸš€ El dashboard estÃ¡ funcionando perfectamente con Aiven")
            print("   ğŸš€ Los Ã­ndices estÃ¡n optimizando las consultas")
            print("   ğŸš€ Puedes subir a producciÃ³n con total confianza")
        elif tiempo_promedio < 10.0:
            print("âš ï¸  RESULTADO: ACEPTABLE")
            print("   ğŸ’¡ El rendimiento es bueno pero puede mejorar")
            print("   ğŸ’¡ Considera revisar antes de subir")
        else:
            print("âŒ RESULTADO: PROBLEMÃTICO")
            print("   ğŸ”§ El rendimiento no es satisfactorio")
            print("   ğŸ”§ Necesitas mÃ¡s optimizaciÃ³n antes de subir")
    
    print("\nğŸ’¡ RECOMENDACIONES:")
    print("   1. Si el rendimiento es excelente (< 3s) â†’ Sube a producciÃ³n")
    print("   2. Si es aceptable (3-10s) â†’ Considera revisar antes de subir")
    print("   3. Si es problemÃ¡tico (> 10s) â†’ Optimiza mÃ¡s antes de subir")
    
    return True

def main():
    """FunciÃ³n principal"""
    try:
        success = test_dashboard_performance()
        if success:
            print("\nğŸ‰ Pruebas completadas exitosamente")
        else:
            print("\nâŒ Las pruebas no se pudieron completar")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ Pruebas canceladas por el usuario")
    except Exception as e:
        print(f"\nâŒ Error inesperado: {e}")

if __name__ == "__main__":
    main()
